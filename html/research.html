<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width">
    <meta name="keywords" content="photography, music, audio, visual, architecture, research">
    <meta name="author" content="Alexander Koenig">
    <title>koenig</title>
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="../css/research.css">
    <meta name="google-site-verification" content="3fNhSnRURomrLL4r_g32STwN6O09JBvGvwAXsbL57I4" />
</head>

<body>
    <script type="text/javascript" src="../js/image_protection.js"></script>

    <header>
        <div class="container">
            <div id="branding">
                <a href="../index.html">
                    <h2>ak</h2>
                </a>
            </div>
            <nav>
                <ul>
                    <li><a href="../index.html">visual</a></li>
                    <li><a href="audio.html">audio</a></li>
                    <li>
                        <div class="current">
                            <div class="bar"></div>
                            <a href="research.html">research</a>
                        </div>
                    </li>
                    <li><a href="about.html">about</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <div class="content-wrapper">
        <div class="timeline">

            <div class="card left">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 09</span>
                        <span id="time">Summer 2021</span>
                    </div>
                    <div class="card-body">
                        <p>For my Master Thesis in the <a class="link" href="http://biorobotics.harvard.edu">Harvard
                                Biorobotics Lab</a>, I used reinforcement learning to train a three-fingered robotic hand 
                                to refine grasps solely based on tactile and joint position data. We use analytic grasp 
                                stability metrics as well-justified optimization objectives for our algorithms and compare 
                                their performance. Our <a class="link"
                                href="https://arxiv.org/abs/2109.11234">paper</a> is currently under review.                             
                                &mdash; with <a class="link"
                                href="https://hst.mit.edu/faculty-research/faculty/howe-robert">Prof Howe</a>, <a class="link"
                                href="http://lucasjanson.fas.harvard.edu">Prof Janson</a>, and
                            <a class="link" href="http://home.in.tum.de/~menze/">Prof Menze</a>
                        </p>
                        <div class="resources">
                            <a class="resource-link" href="https://arxiv.org/abs/2109.11234"
                                target="blank">pre-print</a>
                            <a class="resource-link" href="../downloads/research/mt_compressed.pdf"
                                target="blank">thesis</a>
                            <a class="resource-link" href="https://github.com/axkoenig/grasp_refinement"
                                target="blank">code</a>
                            <a class="resource-link" href="https://www.youtube.com/watch?v=9Bg8ZEAEOGI"
                                target="blank">video</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/grasp_refinement.png">
            </div>

            <div class="card right">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 08</span>
                        <span id="time">Winter 2020</span>
                    </div>
                    <div class="card-body">
                        <p>In preparation for my research project on robotic grasp refinement, I created a simulator for
                            a robotic hand using Gazebo, C++, and the Robot Operating System (ROS). This open-source
                            simulation stack also calculates various metrics that are useful for grasp analysis. The package is available as a pre-built <a class="link" href="https://hub.docker.com/repository/docker/axkoenig/reflex_stack">Docker container</a>. &mdash;
                            with <a class="link" href="https://hst.mit.edu/faculty-research/faculty/howe-robert">Prof Howe</a>
                        </p>
                        <div class="resources">
                            <a class="resource-link" href="https://github.com/axkoenig/reflex_stack"
                                target="blank">code</a>
                                <a class="resource-link" href="https://hub.docker.com/repository/docker/axkoenig/reflex_stack"
                                    target="blank">docker</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/hand.png">
            </div>

            <div class="card left">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 07</span>
                        <span id="time">Summer 2020</span>
                    </div>
                    <div class="card-body">
                        <p>I worked on COVID-19 detection from chest radiographs as part of the Deep
                            Learning in Medical Imaging course at the <a class="link"
                                href="https://en-engineering.tau.ac.il/biomed">Department of Biomedical Engineering</a>
                            at Tel Aviv University. We compare three approaches: (1) transfer learning with a pre-trained network, (2) anomaly detection using an autoencoder trained on healthy lung images, and (3) multi-task learning of image classification and reconstruction.
                             &mdash; with
                            <a class="link" href="http://www.eng.tau.ac.il/~hayit/">Prof Greenspan</a>
                        </p>
                        <div class="resources">
                            <a class="resource-link" href="../downloads/research/dl4mi_report_compressed.pdf"
                                target="blank">report</a>
                            <a class="resource-link" href="../downloads/research/dl4mi_slides_compressed.pdf"
                                target="blank">slides</a>
                            <a class="resource-link" href="https://github.com/axkoenig/dl4mi" target="blank">code</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/dl4mi.png">
            </div>

            <div class="card right">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 06</span>
                        <span id="time">Summer 2020</span>
                    </div>
                    <div class="card-body">
                        <p>I took part in the Machine Learning in
                            Computer Graphics practical offered by the
                            <a class="link" href="https://en-exact-sciences.tau.ac.il/computer">Blavatnik School of
                                Computer Science</a> at Tel Aviv University. In a small team, we developed a new
                            method for self-supervised class and content disentanglement.
                            &mdash; with <a class="link" href="https://www.cs.tau.ac.il/~dcor/">Prof Cohen-Or</a>
                        </p>
                        <div class="resources">
                            <a class="resource-link" href="../downloads/research/ml4cg_report_compressed.pdf"
                                target="blank">report</a>
                            <a class="resource-link" href="../downloads/research/ml4cg_slides_compressed.pdf"
                                target="blank">slides</a>
                            <a class="resource-link" href="https://github.com/axkoenig/ml4cg" target="blank">code</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/ml4cg.png">
            </div>

            <div class="card left">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 05</span>
                        <span id="time">Winter 2019</span>
                    </div>
                    <div class="card-body">
                        <p>I took part in a course on neuroprosthetics at the TUM <a class="link"
                            href="https://www.ei.tum.de/en/bai/home/">Chair for Bio-inspired Information Processing</a>. 
                            In the practical part, I coded up the infamous Hodgkin-Huxley model and simulated neuronal behavior 
                            with different electrical stimuli. Further, I implemented basic encoding strategies for cochlear implants 
                            and a noise vocode to study the signals as perceived by the patient. 
                             &mdash; with
                            <a class="link" href="https://www.professoren.tum.de/en/hemmert-werner">Prof Hemmert</a>
                        </p>
                        <div class="resources">
                            <a class="resource-link" href="../downloads/research/neuro_compressed.pdf" target="blank">reports</a>
                            <a class="resource-link" href="https://github.com/axkoenig/neuroprosthetics" target="blank">code</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/neuro.png">
            </div>

            <div class="card right">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 04</span>
                        <span id="time">Winter 2019</span>
                    </div>
                    <div class="card-body">
                        <p>In my master's, I took part in TUM's software-engineering practical <a class="link"
                                href="https://ase.in.tum.de/lehrstuhl_1/people/people-archive/134-teaching/winterterm-2019-2020/1063-ipraktikum-ws1920">iPraktikum</a>.
                                Our team built the community-based application LocalHero for the German Red Cross in cooperation with an industry partner. The system
                            connects people in need of general
                            assistance or with urgent medical emergencies with helping users around them. &mdash; with
                            <a class="link" href="https://www.professoren.tum.de/en/bruegge-bernd/">Prof Brügge</a>
                        </p>
                        <div class="resources">
                            <a class="resource-link" href="https://youtu.be/Hd8rgOIprww?t=496" target="blank">video
                                1</a>
                            <a class="resource-link" href="https://youtu.be/B3cZeolpBLQ?t=289" target="blank">video
                                2</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/ipraktikum.png">
            </div>

            <div class="card left">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 03</span>
                        <span id="time">Winter 2019</span>
                    </div>
                    <div class="card-body">
                        <p>In the master's seminar Applied Deep Learning in Natural Language
                            Processing at the chair for <a class="link"
                                href="http://politicaldatascience.blogspot.com">Political Data Science</a>, I improved an
                            existing approach to
                            generate word embeddings. I used this system to compare gender bias in religious texts.
                            &mdash; with <a class="link"
                                href="https://www.hfp.tum.de/en/professorships/associate-professor-for-political-data-science/">Prof
                                Hegelich</a>
                        </p>
                    </div>
                    <div class="resources">
                        <a class="resource-link" href="../downloads/research/nlp_compressed.pdf"
                            target="blank">slides</a>
                        <a class="resource-link" href="https://github.com/axkoenig/word_embeddings"
                            target="blank">code</a>
                    </div>
                </div>
                <img src="../images/research/nlp.png">
            </div>

            <div class="card right">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 02</span>
                        <span id="time">Summer 2019</span>
                    </div>
                    <div class="card-body">
                        <p>During my research internship at the <a class="link"
                                href="http://www.imperial.ac.uk/mechatronics-in-medicine">Mechatronics in Medicine
                                Lab</a> at Imperial College
                            London, I built a modular ROS platform to intuitively control a robotic rig with a gesture
                            tracker. Visual feedback via a virtual reality headset allows for remote teleoperation of the robot. I also used data from an RGB-D camera to play with ideas regarding autonomous robotic grasping. 
                            The <a class="link"
                            href="https://ro-man2021.org">IEEE RO-MAN</a> conference 2021 accepted our <a class="link"
                            href="../downloads/research/roman_paper.pdf">paper</a> on the educational use of this platform. &mdash; with <a class="link"
                            href="https://www.imperial.ac.uk/people/r.secoli">Dr Secoli</a> and <a class="link"
                            href="https://www.imperial.ac.uk/people/f.rodriguez">Prof Rodriguez y Baena</a>
                        </p>
                        <div class="resources">
                            <a class="resource-link" href="../downloads/research/roman_paper.pdf"
                                target="blank">paper</a>
                            <a class="resource-link" href="https://www.youtube.com/watch?v=fNvErR5eUpc"
                                target="blank">talk</a>
                            <a class="resource-link" href="https://github.com/axkoenig/leap_teleop"
                                target="blank">code</a>
                            <a class="resource-link" href="../downloads/research/handbook_compressed.pdf"
                                target="blank">handbook</a>
                            <a class="resource-link"
                                href="https://www.dropbox.com/s/5obgwuga39lzid9/project_video.mp4?dl=0"
                                target="blank">video</a>
                            <a class="resource-link"
                                href="https://www.imperial.ac.uk/mechatronics-in-medicine/research/human-robot-interaction-for-object-manipulation/"
                                target="blank">article</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/imperial.png">
            </div>

            <div class="card left">
                <div class="card-content">
                    <div class="card-head">
                        <span class="german-heading">Projekt 01</span>
                        <span id="time">Summer 2018</span>
                    </div>

                    <div class="card-body">
                        <p>For my Bachelor Thesis at the <a class="link"
                                href="http://campar.in.tum.de/Main/NarvisLabNew">NARVIS Lab</a>, I developed an
                            application for the Microsoft HoloLens to
                            support orthopedic trauma surgeons with intra-operative 3D visualizations of complex bone
                            fractures. I conducted a user study with four trauma surgeons to evaluate my work.
                            &mdash; with <a class="link" href="http://campar.in.tum.de/Main/UlrichEck">Dr
                                Eck</a> and <a class="link" href="https://www.professoren.tum.de/en/navab-nassir/">Prof
                                Navab</a></p>
                        <div class="resources">
                            <a class="resource-link" href="../downloads/research/bt_compressed.pdf"
                                target="blank">thesis</a>
                            <a class="resource-link" href="../downloads/research/bt_slides_compressed.pdf"
                                target="blank">slides</a>
                            <a class="resource-link" href="https://www.youtube.com/watch?v=WQMYF8R2ZdI"
                                target="blank">video</a>
                        </div>
                    </div>
                </div>
                <img src="../images/research/bt.png">
            </div>
        </div>
    </div>
</body>

</html>